# To add new prompts simply add the file into one of the subdirectories in ./prompts
SYSTEM_PROMPT = """optional: Specify a path to a system prompt at runtime. 
info: Define the AI assistant's persona, scope of knowledge, and format for output."""
TEMPERATURE = """default: 0.7
type: float
range: (0, 2.0)     
info: Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and 
deterministic."""
TOP_P = """\ndefault:1
type: float
range: (0.1, 1)
info: 
A top_p value of 0.1 means only the tokens comprising the top 10%% probability mass are considered."""
FREQUENCY_PENALTY = """default: 0
type: float
range: (-2,0, 2.0)
info: Positive values decrease the model's likelihood to repeat the same line verbatim."""
PRESENCE_PENALTY = """default: 0
type: float
range: (-2.0, 2.0)      
info: Positive values increase the model's likelihood to talk about new topics."""
# LOGIT_BIAS = """
# Modify the likelihood of specified tokens appearing in the completion. \
# Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) \
# to an associated bias value from -100 to 100. Mathematically, the bias is added to the \
# logits generated by the model prior to sampling. The exact effect will vary per model, \
# but values between -1 and 1 should decrease or increase likelihood of selection; values \
# like -100 or 100 should result in a ban or exclusive selection of the relevant token."""
MAX_TOKENS = """default: 1000
type: int
range: (1, 4096)
info: The maximum number of tokens to generate in the chat completion."""
N = """\ndefault: 1
type: int
range: (1, 20)
info: How many chat completion choices to generate for each input message. Keep n as 1 to minimize costs."""
MODEL = """default: 'gpt-3.5-turbo'
options: ['gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo']
info: The OpenAI API is powered by a diverse set of models with different capabilities."""
# STOP = """
# Up to 4 sequences where the API will stop generating further tokens."""
LOG_LEVEL = """default: 2
type: int
options: (1, 2)
Log level 1: save API response object as a string 
Log level 2: saves the user and assistant messages."""
LOG_FORMAT = """default: 'json'
options: : ['json', 'txt']
info: txt is only available for log-level 2 messages and reply's from GPT."""
MORE_INFO = """
Additional information:

Please note: OpenAI generally recommend altering top_p or temperature, not both.

To learn more about using hkrsAI, please visit:
https://github.com/0x00wolf/hkrsAI

To learn more about GPT models, go to: 
https://platform.openai.com/docs/models/overview

For more information on API parameters please visit: 
https://platform.openai.com/docs/guides/text-generation/parameter-details
"""
DESCRIPTION = """The keep it simple approach to harnessing ChatGPT in your Linux terminal."""
USAGE = """python ./hkrsai.py -h to view this message\n\n"""
